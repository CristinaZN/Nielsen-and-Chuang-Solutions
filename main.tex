\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{physics}
\usepackage{qcircuit}
\usepackage{bbold}
\usepackage{indentfirst}

\setlength{\parskip}{1em}

\newcommand{\mc}[1]{\mathcal{#1}}

\title{Nielsen and Chuang Solutions}
\author{Jacob Watkins}
\date{December 2020}

\begin{document}

\maketitle
\section{Outline and plan}
There exist other partial solution manuals to N\&C, most of them on github. It appears, taken together, they have covered chapters 2,3,4 and 9 almost completely, with scattered solutions for other chapters. Here, we wish to help fill in the gaps, and perhaps ultimately create the most comprehensive solution manual to date. The strategy here is as follows:
\begin{itemize}
    \item Create solution manuals for chapters 5-8
    \item Create solutions for chapters 10-12
    \item (If motivated) Fill in remaining problems in chapters already covered by others (in chapters 2-4 for example.)
    \item (If REALLY motivated) Compile together solutions already created, and bring them into a common format, so that we may come closer to a universal solutions manual!
\end{itemize}
\section{To-do}
\begin{itemize}
    \item Fix QFT circuit, recreate it in Qiskit and set barrier option to True
    \item Double check circuit shown in problem 5.4
\end{itemize}

\section*{Chapter 5: The Quantum Fourier Transform and its applications}

\subsection*{5.1}
\textbf{Problem:} Give a direct proof that the linear transformation defined by Equation (5.2) is unitary.

\textbf{Solution:} It suffices to show that, for any two computational basis states $\ket{j}, \ket{k}$,

\begin{align} \label{eq:5.1:QFT_unitary}
    \bra{j}(QFT)^\dagger(QFT)\ket{k} = \braket{j}{k} = \delta_{ij}.
\end{align}

To do this, we substitute the definition into the above equation. 
\begin{align} \label{eq:5.1:expand_and_simplify}
\begin{aligned}
    \bra{k}(QFT)^\dagger(QFT)\ket{j} &= \Big(\frac{1}{\sqrt{N}}\sum_{p=0}^{N-1}e^{-2\pi ikp/N}\bra{p}\Big)\Big(\frac{1}{\sqrt{N}}\sum_{q=0}^{N-1}e^{2\pi ijq/N}\ket{q}\Big) \\
    &= \frac{1}{N}\sum_{p=0}^{N-1}\sum_{q=0}^{N-1}e^{2\pi i(jq-kp)/N}\braket{p}{q} \\
    &= \frac{1}{N}\sum_{p=0}^{N-1} e^{2\pi i (j-k)p/N}
\end{aligned}
\end{align}
where in the last step we used the orthonormality of the $p,q$ states to eliminate one of the sums. Clearly, if $j=k$, the result is exactly one, as desired. Otherwise, $j-k$ is a nonzero integer, say $n$, such that $\abs{n}<N$. We will show that in this case the sum above is zero. 

The basic idea is that we are taking a sum over phases which are symmetrically distributed around the unit circle, so the result must be zero. To make this argument rigorous, multiply the sum by $e^{2\pi i n/N}$.
\begin{align}
    e^{2\pi i n/N}\sum_{p=0}^{N-1}\big(e^{2\pi i n/N}\big)^p = \sum_{p=0}^{N-1}\big(e^{2\pi i n/N}\big)^{p+1} = \sum_{p=1}^{N}\big(e^{2\pi i n/N}\big)^{p}
\end{align}
In the last equation we simply reindexed. Because of the $N$-periodicity, $\big(e^{2\pi i n/N}\big)^N = 1 = \big(e^{2\pi i n/N}\big)^0$. Hence, we see that the sum is left unchanged by the multiplication. Since $e^{2\pi i n/N} \neq 1$, the sum must in fact be zero. This completes the proof.

\subsection*{5.2}
\textbf{Problem:} Explicitly compute the Fourier transform of the $n$ qubit state $\ket{00...0}$.

\textbf{Solution:} Suppose there are $n$ qubits, so that $N=2^n$. Using the definition given directly above in the textbook,
\begin{align}
    \ket{00...0} &\rightarrow \frac{1}{2^{n/2}} \sum_{k=0}^{2^n-1}e^0 \ket{k} \\
    &= \frac{1}{2^{n/2}}\sum_{k=0}^{2^n-1}\ket{k},
\end{align}
which is simply a uniform superposition over the computational basis states. Evidently, the QFT on the zero state simply acts the same as Hadamards on all the qubits!

We remark that this result is consistent with the interpretation that the Fourier transform decomposes a ``signal" into its frequency components. Here, the signal was a sharp spike, which requires an large spread in frequency to construct. Conversely, a uniform superposition without phases is like a constant function signal, which has a frequency of zero. 

\subsection*{5.3} 
\textbf{Problem (Classical fast Fourier transform)}: Suppose we wish to perform a Fourier transform of a vector containing $2^n$ complex numbers on a classical computer. Verify that the straightforward method for performing the Fourier transform, based upon direct evaluation of Equation (5.1) requires $\Theta(2^{2n})$ elementary arithmetic operations. Find a method for reducing this to $\Theta(n2^n)$ operations, based upon Equation (5.4).
There are $2^n$ complex numbers we need to compute, which are the output amplitudes of the Fourier transform. If we compute each one using (5.1), each such amplitude involves a sum which contains $2^n$ terms. Thus, there will be $2^n \times 2^n = 2^{2n}$ summations and therefore at least as many arithmetic operations.

\textbf{Solution:} Let's now consider a computation based on the factored form of the QFT, Equation (5.4). As before, this involves a computation of $2^n$ amplitudes, one for each bitstring $k = k_1k_2...k_n$. Using (5.4) the amplitude $a_{k}$ corresponding to the state $\ket{k}$ is given by
\begin{align}
    \bra{k}QFT\ket{j} = \frac{1}{2^{n/2}}\big(\delta_{k_1 0}+e^{2\pi i0.j_n}\delta_{k_1 2}\big)\big(\delta_{k_2 0}+e^{2\pi i0.j_{n-1}j_n}\delta_{k_2 2}\big)...\big(\delta_{k_n 0}+e^{2\pi i0.j_1...j_n}\delta_{k_n 2}\big).
\end{align}
where $\ket{j}$ is our input state. This involves a multiplication of $n$ terms, hence there are $n\times 2^n$ total multiplications. This is a lower bound for the number of operations. 

\subsection*{5.4}
\textbf{Problem:} Give a decomposition of the controlled-$R_k$ gate into single qubit and \text{CNOT} gates.

\textbf{Solution:} We use the $ABC$ construction of Corollary 4.2 to make our controlled $R_k$ according to Figure 4.6. First, note that
\begin{align}
    R_k = 
    \begin{pmatrix}
        1 & 0\\
        0 & e^{2\pi i/2^k}\\
    \end{pmatrix} = e^{2\pi i/2^{k+1}}
    \begin{pmatrix}
        e^{-2\pi i/2^{k+1}} & 0 \\
        0 & e^{2\pi i/2^{k+1}}
    \end{pmatrix} = e^{i\alpha}R_z(\beta)
\end{align}
where $\alpha = 2\pi/2^{k+1}$ and $\beta = 2\pi/2^k$. Comparing this to the Euler decomposition formula of Theorem 4.1, we set $\gamma =\delta = 0$. Following through the steps, this implies,
\begin{align}
\begin{aligned}
    A &= R_z(\beta) \\
    B &= R_z(-\beta/2)\\
    C &= R_z(-\beta/2)
\end{aligned}
\end{align}
can be used in the $ABC$ construction of $R_k$. As a final step, primarily one of cosmetics, we notice these gates are related to the $R_k$ through global phases which cancel each other out. Thus, the following circuit implements the controlled-$R_k$, as is easy to verify.
\begin{align}
    \Qcircuit @C=1em @R=1.6em {
        \qw & \ctrl{1} & \qw & & & \qw & \qw & \ctrl{1} & \qw & \ctrl{1} & \gate{R_{k+1}} & \qw\\
        \qw & \gate{R_k} & \qw & \raisebox{2.2em}{=} & & \qw & \gate{R_{k+1}^\dagger} & \targ & \gate{R_{k+1}^\dagger} & \targ & \gate{R_k} & \qw
    } 
\end{align}

\subsection*{5.5} 
\textbf{Problem:} Give a quantum circuit to perform the inverse quantum Fourier transform.

\textbf{Solution:} Here is the circuit for six qubits (generated using qiskit).
\begin{equation*}
    \Qcircuit @C=1.0em @R=0.0em @!R {
	 	\lstick{ {q}_{0} :  } \barrier[0em]{5} & \qw & \qw \barrier[0em]{5} & \qw & \qw & \qw & \qw \barrier[0em]{5} & \qw & \qw & \qw & \qw & \qw & \qw \barrier[0em]{5} & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw \barrier[0em]{5} & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw \barrier[0em]{5} & \qw & \ctrl{5} & \dstick{\frac{-\pi}{32}}\qw & \ctrl{4} & \dstick{\frac{-\pi}{16}}\qw & \ctrl{3} & \dstick{\frac{-\pi}{8}}\qw & \ctrl{2} & \dstick{\frac{-\pi}{4}}\qw & \ctrl{1} & \dstick{\frac{-\pi}{2}}\qw & \gate{H} & \qw & \qw\\
	 	\lstick{ {q}_{1} :  } & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \ctrl{4} & \dstick{\frac{-\pi}{16}}\qw & \ctrl{3} & \dstick{\frac{-\pi}{8}}\qw & \ctrl{2} & \dstick{\frac{-\pi}{4}}\qw & \ctrl{1} & \dstick{\frac{-\pi}{2}}\qw & \gate{H} & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw\\
	 	\lstick{ {q}_{2} :  } & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \ctrl{3} & \dstick{\frac{-\pi}{8}}\qw & \ctrl{2} & \dstick{\frac{-\pi}{4}}\qw & \ctrl{1} & \dstick{\frac{-\pi}{2}}\qw & \gate{H} & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \qw\\
	 	\lstick{ {q}_{3} :  } & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \ctrl{2} & \dstick{\frac{-\pi}{4}}\qw & \ctrl{1} & \dstick{\frac{-\pi}{2}}\qw & \gate{H} & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw\\
	 	\lstick{ {q}_{4} :  } & \qw & \qw & \qw & \ctrl{1} & \dstick{\frac{-\pi}{2}}\qw & \gate{H} & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw\\
	 	\lstick{ {q}_{5} :  } & \qw & \gate{H} & \qw & \control \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \control \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw & \qw\\
	 }
\end{equation*}
Here, the vertical line segments are the $R_k$ gates, where the number alongside indicate angle of phase rotated. Like the inverse to any quantum circuit, can be obtained by reversing the order of the gates and taking the inverse of each gate. Note the Hadamard $H$ is self-inverse.

\subsection*{5.6}
\textbf{Problem (Approximate quantum Fourier transform):} The quantum circuit construction of the quantum Fourier transform apparently requires gates of exponential precision in the number of qubits used. However, such precision is never required in any quantum circuit of polynomial size. For example, let $U$ be the ideal quantum Fourier transform on $n$ qubits, and $V$ be the transform which results if the controlled-$R_k$ gates are performed to a precision $\Delta = 1/p(n)$ for some polynomial $p(n)$. Show that the error $E(U, V) \equiv max_{\ket{\psi}} \left\|(U - V)\ket{\psi}\right\|$ scales as $\Theta(n^2/p(n))$, and thus polynomial precision in each gate is sufficient to guarantee polynomial accuracy in the output state.

\textbf{Solution:} First we will show a more general result (one which will be further generalized in part 3 of the book, when discussing quantum channels). Let $\mc{X}$ and $\mc{Y}$ be quantum gates, and let $X$ and $Y$ be gates which we will think of as approximating $\mc{X}$ and $\mc{Y}$ respectively. We will show that
\begin{align}
    E(\mc{XY},XY) \leq E(\mc{X},X) + E(\mc{Y},Y).
\end{align}
To proceed, we set things up to make use of our friend: the triangle inequality. For any state $\ket{\psi}$ we have
\begin{align}
    \left\|(\mc{XY}-XY)\ket{\psi}\right\|&=\left\|(\mc{X}\mc{Y}-X\mc{Y}+X\mc{Y}-XY)\ket{\psi}\right\| \\
    &= \left\|(\mc{X}-X)\mc{Y}\ket{\psi}+X(\mc{Y}-Y)\ket{\psi}\right\| \\
    &\leq \left\|(\mc{X}-X)\mc{Y}\ket{\psi}\right\|+\left\|X(\mc{Y}-Y)\ket{\psi}\right\|
\end{align}
Since this inequality holds for any $\ket{\psi}$, it certainly holds if we take the max of both sides. Hence,
\begin{align}
    E(\mc{XY},XY) \leq \max_{\ket{\psi}} \left(\left\|(\mc{X}-X)\mc{Y}\ket{\psi}\right\|+\left\|X(\mc{Y}-Y)\ket{\psi}\right\|\right)
\end{align}
Certainly, the maximum of a sum $A+B$ is less than (or equal to) maximizing each individual piece $A,B$, so we may distribute the $\max$ function and maintain the inequality. Let's consider each term on the left hand side. Since $\mc{Y}$ is unitary, it is a bijection on the space of valid states. Hence, we can maximize over $\ket{\phi} = \mc{Y}\ket{\psi}$ instead. Now consider the rightmost term. Since $X$ is unitary, it preserves norm. Altogether,
\begin{align}
     E(\mc{XY},XY) &\leq \max_{\ket{\phi}}\left\|(\mc{X}-X)\ket{\phi}\right\| + \max_{\ket{\psi}}\left\|(\mc{Y}-Y)\ket{\psi}\right\|\\
     &= E(\mc{X},X) + E(\mc{Y},Y).
\end{align}
This places a bound on the error when composing imperfect gates. Moreover, this bound is tight, since if $X=\mc{X}$ and $Y=\mc{Y}$ we get strict equality. 
We can generalize this result, by simple induction, to arbitrary sequences of gates with corresponding approximations. Thus, in our present case, if each controlled $R_k$ has precision $\Delta$, 
\begin{align}
    E(U,V) \leq \frac{n(n+1)}{2}\Delta \in \Theta(n^2 \Delta).
\end{align}
Here, the use of $\Theta$ is appropriate rather than $\mc{O}$ since our bound is tight.

\subsection*{5.7}
\textbf{Problem:} Additional insight into the circuit in Figure 5.2 may be obtained by showing, as you should now do, that the effect of the sequence of controlled-$U$ operations like that in Figure 5.2 is to take the state $\ket{j}\ket{u}$ to $\ket{j}U^j\ket{u}$. (Note that this does not depend on $\ket{u}$ being an eigenstate of $U$.)

\textbf{Solution:} Suppose there are $t$ qubits in the first register, so the integer $j$ can be expressed in binary as $j_{t-1}...j_1j_0$, with $j_k \in \{0,1\}$ for every $0\leq k < t$. By definition, this means $j = j_0 + 2j_1 + ... + 2^{t-1}j_{t-1}$. The state $\ket{j}$ has tensor product form
\begin{align}
    \ket{j} = \bigotimes_{k=0}^{t-1} \ket{j_k} \equiv \ket{j_{t-1}}...\ket{j_{0}}.
\end{align}
The action of the controlled-$U^2k$ controlled on the $k$th qubitis given by
\begin{align}
    \ket{j_k}\ket{u} \longrightarrow  \ket{j_k} U^{2^k j_k}\ket{u}
\end{align}
as can be readily verified. Thus, the full sequence of controlled gates acts as follows.
\begin{align}
\begin{aligned}
    \ket{j}\ket{u} = \bigotimes_{k=0}^{t-1} \ket{j_k}\ket{u} \longrightarrow &\ket{j}U^{2^{t-1}j_{t-1}}...U^{2^0 j_0}\ket{u} \\
    = &\ket{j}U^{2^0 j_0 + ... + 2^{t-1} j_{t-1}}\ket{u} \\
    = &\ket{j}U^j\ket{u}
\end{aligned}
\end{align}
In the last step we reused the definition of $j$ being expressed in binary. This gives the desired result, which, as we see, did not rely on particular knowledge of the state $\ket{u}$.

\subsection*{5.8}
\textbf{Problem:} Suppose the phase estimation algorithm takes the state $\ket{0}\ket{u}$ to the state $\ket{\tilde{\varphi}_u}\ket{u}$, so that the input $\ket{0}\big(\sum_u c_u\ket{u}\big)$, the algorithm outputs $\sum_u c_u\ket{\tilde{\varphi}_u}\ket{u}$. Show that if $t$ is chosen according to (5.35), then the probability for measuring $\varphi_u$ accurate to $n$ bits at the conclusion of the phase estimation algorithm is at least $\abs{c_u}^2(1-\epsilon)$.

\textbf{Solution:} If $t$ is chosen as such, then $\tilde{\varphi}_u$ is an $n$-bit approximation to $\varphi_u$ with probability $p_{succ} \geq (1-\epsilon)$. Meanwhile, the probability of measuring $\tilde{\varphi}_u$ on the first register is given by the Born rule: $p_u = \abs{c_u}^2$. These two events are independent, hence, the probability of measuring $\tilde{\varphi}_u$ \emph{and} having it be an $n$-bit approximation is
\begin{align} \label{eq:lower bound}
    p_u p_{succ} \geq \abs{c_u}^2 (1-\epsilon).
\end{align}
Moreover, any other eigenstate $\ket{v}$ of $U$ such that $\varphi_v \neq \varphi_u$ might still result in an $n$-bit approximation to $\varphi_u$, provided they are sufficiently close (it may even be that $\tilde{\varphi}_v = \tilde{\varphi}_u$). This will only further increase the probability of success. In any case, the right side of \eqref{eq:lower bound} remains a lower bound. 

\subsection*{5.9}
\textbf{Problem:} Let $U$ be a unitary transform with eigenvalues $\pm 1$, which acts on a state $\ket{\psi}$. Using the phase estimation procedure, construct a quantum circuit to collapse $\ket{\psi}$ into one or the other of the two eigenspaces of $U$, giving also a classical indicator as to which space the final state is in. Compare your result with Exercise 4.34.

\textbf{Solution:} If the eigenvalues of $U$ are $1$ and $-1$, the corresponding phases are $0.0$ and $0.1$ respectively. Because these phases are finite bitstrings, there is no possibility of error and, in fact, we can take $t = n$, which in our case is $1$. The inverse-QFT on one qubit is simply the Hadamard, and our circuit reduces to the following.
\begin{align}
    \Qcircuit @C=1.0em @R=1.6em{
        \lstick{\ket{0}} & \gate{H} & \ctrl{1} & \gate{H} & \meter & \qw \\
        \lstick{\ket{\psi}} & \qw & \gate{U} & \qw & \qw & \qw
    }
\end{align}
If a $0$ ($1$) is measured, the final state is known to be in the plus (minus) subspace. The probability of each outcome is simply related to the initial overlap with each subspace via the Born rule. 

\subsection*{5.10}
\textbf{Problem:} Show that the order of $x=5$ modulo $N=21$ is 6.

\textbf{Solution:} We proceed by exhaustive calculation.
\begin{align}
\begin{aligned}
    5^1 \bmod 21 &= 5 \\
    5^2 \bmod 21 &= 4 \\
    5^3 \bmod 21 &= 20\\
    5^4 \bmod 21 &= 16\\
    5^5 \bmod 21 &= 17\\
    5^6 \bmod 21 &= 1
\end{aligned}
\end{align}
Hence, 6 is the smallest positive integer $r$ such that $5^r \bmod 21 = 1$. Thus, 6 is the order of 5 modulo 21.

\subsection*{5.11}
\textbf{Problem:} Show that the order of $x$ satisfies $r\leq N$.

\textbf{Solution:} Consider the set $\{x^n \bmod N\}_{n=1}^N$. Because we assume $x$ and $N$ share no common factors, it is not possible for $x^n \bmod N = 0$. Hence, $0< x^n \bmod N < N$. By the pigeonhole principle, not all the values for $x^n \bmod N$ can be unique. There must exist some $x^i = x^j \bmod N$ for some $1\leq i,j \leq N$ and $j\neq i$. Assume $j>i$ without loss of generality. Then, we have
\begin{align}
\begin{aligned}
    x^j-x^i &= 0 \bmod N \\
    x^i(x^{j-i}-1) &=0 \bmod N.
\end{aligned}
\end{align}
This implies $N|x^i(x^{j-i}-1)$. But $N\nmid x^i$, again by assumption of no common factors. Hence, we must have $N|(x^{j-i}-1)$, or $x^{j-i} = 1 \bmod N$. Since $r$ is the smallest integer satisfying this condition, we must have $r\leq j-i < N$. Note this is a strict inequality, unlike what is given in the text.

\subsection*{5.12}
\textbf{Problem:} Show that $U$ is unitary (Hint: $x$ is co-prime to $N$, and therefore has an inverse modulo $N$).

\textbf{Solution:} Since $U$ acts as a map on the computational basis states, it suffices to show this map is injective (one-to-one). If $y\geq N$, then $\ket{y}$ is mapped to itself. On the other hand, if $0\leq y < N$, then $\ket{y}$ is certainly mapped to some $\ket{z}$ where $z< N$. Hence, $U$ is injective on the subspace where $y\geq N$, and it suffices to focus on the case where $y< N$. To this end, suppose $U\ket{y} = U\ket{z}$ for $y,z < N$. Then,
\begin{align}
\begin{aligned}
    xy\bmod{N} &= xz\bmod{N} \\
    x(y-z) &= 0 \pmod{N}
\end{aligned}
\end{align}
This implies $N$ divides $x(y-z)$. However, since $N$ and $x$ are coprime, they share no common factors. This implies $N|(y-z)$. But $|y-z| < N$, so it must be that $y-z = 0$. Hence
\begin{align}
    \ket{y} = \ket{z}
\end{align}
which proves that $U$ is injective on the basis, as desired.

\subsection*{5.13}
\textbf{Problem:} Prove (5.44). (\emph{Hint}:$\sum_{s=0}^{r-1}\exp(-2\pi i sk/r)=r\delta_{k0}$). In fact, prove that
\begin{align}
    \frac{1}{\sqrt{r}}\sum_{s=0}^{r-1}e^{2\pi isk/r}\ket{u_s} = \ket{x^k\bmod N}
\end{align}

\textbf{Solution:} Let us crank the wheel: putting in the definition of $\ket{u_s}$ to the left side of (5.44) and regrouping.
\begin{align}
    \frac{1}{\sqrt{r}}\sum_{s=0}^{r-1}e^{2\pi isk/r}\ket{u_s} &= \frac{1}{\sqrt{r}}\sum_{s=0}^{r-1}e^{2\pi isk/r} \frac{1}{\sqrt{r}}\sum_{t=0}^{r-1}e^{-2\pi ist/r}\ket{x^t\bmod N} \\
    &= \frac{1}{r}\sum_{s=0}^{r-1}\sum_{t=0}^{r-1}e^{2\pi is(k-t)/r}\ket{x^t\bmod N} \\
    &=\frac{1}{r}\sum_{t=0}^{r-1}\ket{x^t\bmod N}\Big(\sum_{s=0}^{r-1}e^{2\pi is(k-t)/r}\Big)
\end{align}
Making gracious use of the hint, we see the rightmost sum on the last line equals $r\delta_{kt}$. Hence,
\begin{align}
    \frac{1}{\sqrt{r}}\sum_{s=0}^{r-1}e^{2\pi isk/r}\ket{u_s} &= \sum_{t=0}^{r-1}\delta_{tk}\ket{x^t \bmod N} \\
    &= \ket{x^k \bmod N}.
\end{align}
To obtain (5.44) from the text, simply set $k=0$.

\subsection*{5.14}
\textbf{Problem:} The quantum state produced in the order-finding algorithm, before
the inverse Fourier transform, is
\begin{align}
    \ket{\psi} =\sum_{j=0}^{2^t-1}\ket{j}U^j\ket{1} =\sum_{j=0}^{2^t-1}\ket{j}\ket{x^j\bmod N}
\end{align}
if we initialize the second register as $\ket{1}$. Show that the same state is obtained if we replace $U^j$ with a \emph{different} unitary transform $V$, which computes
\begin{align}
    V\ket{j}\ket{k} = \ket{j}\ket{k+x^j\bmod N},
\end{align}
and start the second register in the state $\ket{0}$. Also show how to construct $V$ using $O(L^3)$ gates.

\textbf{Solution:} It is obvious that, by setting $k=0$, we obtain the same output using $V$ as we would if $k=1$ and we had acted with $U$. Finding $V$ is going to require techniques in reversible computation. 

\section*{Chapter 6: Quantum Search Algorithms}
\subsection*{6.1} 
\textbf{Problem:} Show that the unitary operator corresponding to the phase shift in the Grover iteration is $(2\ket{0}\bra{0}-I)$.

\textbf{Solution:} For $\ket{x} = \ket{0}$,
\begin{align}
    (2\ket{0}\bra{0}-I)\ket{0} = 2\ket{0}-\ket{0} = \ket{0}
\end{align}
Meanwhile, for $\ket{x} \neq \ket{0}$,
\begin{align}
    (2\ket{0}\bra{0}-I)\ket{x} = 2\ket{0}\braket{0}{x}-\ket{x} = -\ket{x}
\end{align}
Altogether,
\begin{align}
    (2\ket{0}\bra{0}-I)\ket{x} = (-1)^{\delta_{0x}}\ket{x}
\end{align}

\subsection*{6.2}
\textbf{Problem:} Show that the operation $(2\ket{\psi}\bra{\psi}-I)$ applied to a general state $\sum_k \alpha_k \ket{k}$ produces
\begin{align}
    \sum_k \left(-\alpha_k+2\langle\alpha\rangle\right)\ket{k}
\end{align}
where $\langle\alpha\rangle \equiv \sum_k\alpha_k/N$ is the mean value of the $\alpha_k$. For this reason, $(2\ket{\psi}\bra{\psi}-I)$ is sometimes referred to as the \emph{inversion about mean} operation.

\textbf{Solution:} By linearity,
\begin{align*}
    (2\ket{\psi}\bra{\psi}-I)\sum_k \alpha_k\ket{k} &= \sum_k 2 \alpha_k\left(\ket{\psi}\bra{\psi}\right)\ket{k} - \sum_k \alpha_k\ket{k} \\
    &= 2\ket{\psi}\sum_k\alpha_k\braket{\psi}{k}-\sum_k\alpha_k\ket{k}
\end{align*}
Because $\ket{\psi}$ is uniform superposition over the computational basis states, for all $k$ we have $\braket{\psi}{k}=1/\sqrt{N}$. Hence,
\begin{align}
(2\ket{\psi}\bra{\psi}-I)\sum_k \alpha_k\ket{k} &= \frac{2}{\sqrt{N}}\left(\sum_k\alpha_k\right)\ket{\psi} - \sum_k \alpha_k\ket{k} \\
&= 2\sqrt{N} \langle\alpha\rangle\ket{\psi} - \sum_k\alpha_k\ket{k}
\end{align}
Finally, we expand out the definition of $\ket{\psi}$ and cancel the factors of $\sqrt{N}$.This gives our result. 
\begin{align}
    2\sqrt{N} \langle\alpha\rangle\ket{\psi} - \sum_k\alpha_k\ket{k} &= \sum_k\left(2\langle\alpha\rangle-\alpha_k\right)\ket{k}
\end{align}

\subsection*{6.3}
\textbf{Problem:} Show that in the $\ket{\alpha}, \ket{\beta}$ basis, we may write the Grover iteration as
\begin{align}
    G = 
    \begin{bmatrix} \label{eq:matrix_G}
        \cos\theta & -\sin\theta \\
        \sin\theta & \cos\theta
    \end{bmatrix}
\end{align}
where $\theta$ is a real number in the range 0 to $\pi/2$ (assuming for simplicity that $M\leq N/2$; this limitation will be lifted shortly), chosen so that
\begin{align} \label{eq:theta_value}
    \sin\theta =\frac{2\sqrt{M(N-M)}}{N}
\end{align}

\textbf{Solution:} As discussed in the text, both the oracle $O$ and the reflection $2\ket{\psi}\bra{\psi}-I$ leave the subspace $V = span\left(\ket{\alpha},\ket{\beta}\right)$ invariant. Hence, so does the product $G$. Therefore, we will from here on speak of $G$ only in terms of its action on the 2-dimensional subspace $V = span\left(\ket{\alpha},\ket{\beta}\right)$, and consider the matrix representation in the orthonormal basis $\{\ket{\alpha},\ket{\beta}\}$. This representation is unitary (since $G$ itself is), and in fact it is orthogonal, since both $O$ and $(2\ket{\psi}\bra{\psi}-I)$ have real matrix elements. More specifically, $G$ is \emph{special} orthogonal, meaning it has determinant one, because it is the product of two reflections. All of this implies $G$ is a proper rotation in the plane, and any such matrix may be parametrized as equation \eqref{eq:matrix_G} for \emph{some} angle $\theta$. It remains to show $\theta$ satisfies relation \eqref{eq:theta_value}. To do this, we simply compute the matrix element $\bra{\beta}G\ket{\alpha}$.
\begin{align}
\begin{aligned}
    \bra{\beta}G\ket{\alpha} &= \bra{\beta}\left(2\ket{\psi}\bra{\psi}-I\right)O\ket{\alpha} \\
    &=\bra{\beta}\left(2\ket{\psi}\bra{\psi}-I\right)\ket{\alpha}\\
    &=\bra{\beta}\left(2\ket{\psi}\braket{\psi}{\alpha}-\ket{\alpha}\right) \\
    &=2\braket{\beta}{\psi}\braket{\psi}{\alpha},
\end{aligned}
\end{align}
where, along the way, we used the orthogonality of $\ket{\alpha},\ket{\beta}$ and the fact that $O\ket{\alpha} = \ket{\alpha}$. Finally, using the expression given in the text for $\ket{\psi}$ expanded in the $\ket{\alpha},\ket{\beta}$ basis, we arrive at our result. 
\begin{align}
    \bra{\beta}G\ket{\alpha} = \sin\theta = \frac{2\sqrt{M(N-M)}}{N}
\end{align}
Note that, in fact, we did not require the assumption that $M\leq N/2$ in our derivation.

\section*{Appendix 1: Notes on basic probability theory}
\subsection*{A1.1} 
\textbf{Problem:} Prove Bayes' rule.

\textbf{Solution:} From the definition of conditional probability, we have
\begin{align}
    p(x,y) = p(y|x)p(x) = p(x|y)p(y)
\end{align}
Rearranging the last of these equations gives the desired result.

\subsection*{A1.2}
\textbf{Problem:} Prove the law of total probability.

\textbf{Solution:} We start with the notion that, in the joint probability distribution for $(X,Y)$, one sums over all outcomes of $X$ to get a probability distribution on $Y$ alone.
\begin{align}
    p(y) = \sum_x p(x,y)
\end{align}
We arrive at our result by noting that, from the definition of conditional probability, $p(x,y) = p(y|x)p(x)$.

\subsection*{A1.3}
\textbf{Problem:} Prove there exists a value of $x\geq\textbf{E}(X)$ such that $p(x)>0$.

\textbf{Solution:} Suppose, for sake of contradiction, that every value $x$ of $X$ with nonzero probability has the property $x < \textbf{E}(X)$. Intuitively, we'd expect that the expectation value would have to be less then $\textbf{E}(X)$. Indeed, using the inequality in the definition of expectation value,
\begin{align}
    \textbf{E}(X) = \sum_{x\in X} x\p(x) < \textbf{E}(X)\sum_{x\in X}p(x) = \textbf{E}(X)
\end{align}
Hence, $\textbf{E}(X)<\textbf{E}(x)$, a clear contradiction. We conclude our premise was false, hence there does exist a value of $x\in X$ such that $x \geq \textbf{E}(X)$ and $p(x)>0$.

\subsection*{A1.4} 
\textbf{Problem:} Prove that $\textbf{E}(X)$ is linear in $X$.

\textbf{Solution:} The following computation gives us the result.
\begin{align}
\begin{aligned}
    \textbf{E}(aX+bY) &= \sum_{(x,y)\in(X,Y)}(ax+by)p(x,y) \\
    &= \sum_{x\in X}\sum_{y\in Y}axp(x,y) + byp(x,y) \\
    &=\sum_{x\in X}ax\sum_{y\in Y}p(x,y) + \sum_{y\in Y}by\sum_{x\in X}p(x,y) \\
    &=a\sum_{x\in X}x p(x) + b\sum_{y\in Y}yp(y) \\
    &=a\textbf{E}(X) + b\textbf{E}(Y).
\end{aligned}
\end{align}
Here, $a,b$ are constants. Along the way, we used $p(x) = \sum_y p(x,y)$ and the definition of expectation value.

\subsection*{A1.5}
\textbf{Problem:} Prove that for independent random variables $X$ and $Y$, \textbf{E}(XY) = \textbf{E}(X)\textbf{E}(Y).

\textbf{Solution:} Recall that, for independent random variables, the joint probability distribution breaks into a product of individual probabilities. This yields the following computation.
\begin{align}
\begin{aligned}
    \textbf{E}(XY) &= \sum_x\sum_y xy\,p(x,y)\\
    &= \sum_x\sum_y xy\,p(x)p(y) \\
    &= \sum_x p(x) \sum_y p(y) \\
    &= \textbf{E}(X)\textbf{E}(Y)
\end{aligned}
\end{align}

\end{document}